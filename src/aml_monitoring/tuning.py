"""Train/tune rule thresholds from ingested transaction data."""

from __future__ import annotations

from collections import defaultdict
from logging import getLogger
from pathlib import Path

from sqlalchemy import select

from aml_monitoring.config import get_config
from aml_monitoring.db import session_scope
from aml_monitoring.models import Transaction

logger = getLogger(__name__)


def _percentile(sorted_values: list[float], p: float) -> float:
    """Return percentile (0..1) from sorted list. Returns 0 if empty."""
    if not sorted_values:
        return 0.0
    idx = min(int(p * len(sorted_values)), len(sorted_values) - 1)
    return sorted_values[max(0, idx)]


def compute_tuned_config(config_path: str | None = None) -> dict:
    """
    Analyze transactions in the DB and compute rule thresholds (high_value,
    rapid_velocity, structuring_smurfing). Returns a config fragment to merge
    (e.g. under rules.*). Does not modify the database.
    """
    _ = get_config(config_path)  # validate config
    out: dict = {"rules": {}}

    with session_scope() as session:
        amounts_row = session.execute(select(Transaction.amount)).fetchall()
        vel_rows = session.execute(
            select(Transaction.account_id, Transaction.ts).order_by(Transaction.id)
        ).fetchall()
    amounts = sorted([abs(r[0]) for r in amounts_row if r[0] is not None])
    if not amounts:
        logger.warning("No transactions in DB; returning base rule defaults.")
        out["rules"]["high_value"] = {"threshold_amount": 1000}
        return out
    p99 = _percentile(amounts, 0.99)
    p95 = _percentile(amounts, 0.95)
    # High-value: 99th percentile, rounded to nearest 1000, floor 1000
    high_val = max(1000.0, round(p99 / 1000) * 1000)
    out["rules"]["high_value"] = {"threshold_amount": int(high_val)}
    # Structuring: just below typical large; use 95th rounded down to 500, floor 1000
    struct_val = max(1000.0, round(p95 / 500) * 500)
    out["rules"]["structuring_smurfing"] = {"threshold_amount": int(struct_val)}

    # Rapid velocity: per-account max txns in 15-min window, then 90th percentile
    window_minutes = 15
    bucket_counts: dict[tuple[int, int], int] = defaultdict(int)
    for acc_id, ts in vel_rows:
        if ts is None:
            continue
        epoch_min = int(ts.timestamp())
        bucket = (epoch_min // (window_minutes * 60)) * (window_minutes * 60)
        bucket_counts[(acc_id, bucket)] += 1
    # Per-account max count in any 15-min window
    account_max: dict[int, int] = defaultdict(int)
    for (acc_id, _), count in bucket_counts.items():
        account_max[acc_id] = max(account_max[acc_id], count)
    max_counts = sorted(account_max.values())
    if max_counts:
        vel_p90 = _percentile([float(x) for x in max_counts], 0.90)
        min_txns = max(3, int(vel_p90) + 1)
        out["rules"]["rapid_velocity"] = {
            "min_transactions": min_txns,
            "window_minutes": window_minutes,
        }

    return out


def write_tuned_config(
    tuned: dict,
    output_path: str | Path = "config/tuned.yaml",
) -> None:
    """Write tuned config fragment to YAML (mergeable over default + dev)."""
    import yaml  # type: ignore[import-untyped]

    path = Path(output_path)
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        f.write("# Auto-generated by 'aml train'. Merged over default + dev. Edit to override.\n")
        yaml.dump(tuned, f, default_flow_style=False, sort_keys=True, allow_unicode=True)
    logger.info("Wrote tuned config to %s", path)


def train(config_path: str | None = None, output_path: str | Path = "config/tuned.yaml") -> dict:
    """
    Compute tuned thresholds from DB and write config/tuned.yaml.
    Returns the tuned fragment (for tests or API).
    """
    tuned = compute_tuned_config(config_path)
    write_tuned_config(tuned, output_path)
    return tuned
